from bs4 import BeautifulSoup
import csv
import sys
import requests
from loguru import logger
import pandas as pd
from datetime import datetime
import numpy as np


logger.add('Detection of phishing URLs.log',
           format='{level} {time:MM-DD HH:mm:ss.SSS} {name}:{function}:{line} {message}',
           level='INFO',
           backtrace=True, diagnose=True, enqueue=True, colorize=True)

i = 0
lifetime_values = []


def days_between(d1, d2):
    d1 = datetime.strptime(d1, "%Y-%m-%dT%H:%M:%fZ")
    d2 = datetime.strptime(d2, "%Y-%m-%dT%H:%M:%fZ")
    return abs((d2 - d1).days)


def parse_phishtank(link_id, savefile):
    global i, lifetime_values
    data = {}
    r = requests.get(f'http://phishtank.org/technical_details.php?phish_id={link_id}')
    response = BeautifulSoup(r.text, 'html.parser')
    try:
        text = response.find_all('pre')
        data['Network'] = text[0].text.split(' ')[0]
        for value in text[1].text.split('\r\n'):
            v = value.split(': ')
            if v[0].strip() in fields:
                data[f'{v[0]}'] = v[1]
        with open(savefile, 'a') as f:
            writer = csv.writer(f)
            if i == 0:  # writing row with key info only for first time
                writer.writerow(data.keys())
            if len(data.values()) == 9:  # checking if all data values are available
                writer.writerow(data.values())
                i += 1
                logger.success(f'Data for {link_id} has been extracted ')
            else:
                logger.warning(f'Data for {link_id} has less then 9 values ')
    except Exception as _e:
        logger.error(_e)


def calculate_lifetime():
    for it in range(i):
        lifetime(it)
    df = pd.read_csv(savefile)
    df['The lifetime of a domain (days)'] = np.resize(lifetime_values,len(df))
    df.to_csv(savefile, index=False)


def lifetime(i):
    df = pd.read_csv(savefile)
    df.to_csv(savefile, index=False)
    df = pd.read_csv(savefile)
    res = days_between(df['Registry Expiry Date'][i], df['Creation Date'][i])
    lifetime_values.append(res)
    return lifetime_values


if __name__ == '__main__':
    fields = ['Domain Name', 'Updated Date', 'Creation Date', 'Registry Expiry Date', 'Registrar', 'Registrant Name',
              'Registrant Organization', 'Registrant Country']
    savefile = 'Detection of phishing URLs.csv'
    start_from_link_id = 1_684_900
    end_with_link_id = 6_685_900

    assert int(end_with_link_id) > int(start_from_link_id), "start_from_link_id can't be higher than end " \
                                                            "end_with_link_id "
    for link_id in list(range(start_from_link_id, end_with_link_id + 1, 10000)):
        parse_phishtank(link_id, savefile)
    calculate_lifetime()
